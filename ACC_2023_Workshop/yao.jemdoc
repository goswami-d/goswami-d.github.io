# jemdoc: menu{MENU}{yao.html}, nofooter
==Predicting Human Intentions through Interaction using Online Learning

=== Speaker

Ningshi Yao

=== Affiliation

Assistant Professor\n
Department of Electrical and Computer Engineering\n
George Mason University

=== Abstract

One of the most challenging problems for robot to effectively interact with human is to reliably predict human intentions. This talk will focus on how to recognize and predict human intentions through interaction data of a robot interacting a human subject repeatedly. I will first present models for a class of expert based online learning algorithms that have been applied to human robot interaction in experiments. Then I will discuss how to better design learning algorithms on the robotâ€™s side so that it can learn the human intentions more effectively and reliably. Multiple human and robot interaction experiments will also be presented in this talk to show the effectiveness of our methods and analysis. The experiments were conducted on the Georgia Tech Miniature Autonomous Blimp (GT-MAB), which is a safe flying vehicle that can support relatively long-time and natural human robot interaction.

=== Bio
~~~
{}{img_left}{photos/Yao.jpg}{alt text}{300}{300}{}
Ningshi Yao is an assistant professor in the Department of Electrical and Computer Engineering at George Mason University. She received her PhD from the School of Electrical and Computer Engineering at Georgia Institute of Technology in 2020, and the BS in Automatic Control from Zhejiang University, China, in 2014. Prior to joining Mason, she was a postdoctoral research fellow at Georgia Institute of Technology from November 2020 to July 2021.

In her research, she developed a novel contention-resolving model predictive control method to co-design scheduling and control for resource-constrained systems, such as networked control systems, traffic intersection management, and human-robot collaborative systems. Her research interests include real-time scheduling, control theory, cyber-physical systems, machine learning and human-robot interaction.
~~~