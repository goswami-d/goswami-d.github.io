<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Optimal Control with Learning on The Fly: System with Unknown Drift</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="program.html">Program</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Optimal Control with Learning on The Fly: System with Unknown Drift</h1>
</div>
<h3>Speaker</h3>
<p>Debdipta Goswami
</p>
<h3>Affiliation</h3>
<p>The Ohio State University
</p>
<h3>Abstract</h3>
<p>Most techniques developed during the past century for estimation and control of dynamical systems require precise knowledge of an underlying mathematical model. But recently, there has been renewed interest in controlling systems for which a reliable model is unknown or the model parameters can vary. Here an optimal control strategy is developed for a simple problem where the drift parameter is unknown and must be learned on the fly while controlling the system. This scenario requires a control strategy from the initial time and cannot accommodate distinct phases of parameter learning and control update. The cost function is posed over a finite time interval, and the state is subject to random disturbances and measured by a noisy sensor. Several different versions of the problem are studied. In the Bayesian version, a prior distribution on the unknown drift parameter is assumed. In the &lsquo;&lsquo;agnostic&rsquo;&rsquo; version, no such assumption is made and the performance is compared against an adversary with exact knowledge of the parameter. This gives rise to several notions of performance penalty or &lsquo;&lsquo;regret&rsquo;&rsquo;. The optimal strategy is chosen
to minimize the &lsquo;&lsquo;worst-case regret&rsquo;&rsquo; arising from the most unfavorable value of the parameter for that strategy. In every case, the optimal strategy turns out to be a Bayesian strategy or a limit of Bayesian strategies. This is a joint work with Clarence W. Rowley and Charles L. Fefferman (Princeton University).
</p>
</td>
</tr>
</table>
</body>
</html>
