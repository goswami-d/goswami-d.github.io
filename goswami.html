<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Optimal Control with Learning on The Fly: System with Unknown Drift</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="program.html">Program</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Optimal Control with Learning on The Fly: System with Unknown Drift</h1>
</div>
<h3>Speaker</h3>
<p>Debdipta Goswami
</p>
<h3>Affiliation</h3>
<p>Assistant Professor<br />
Department of Mechanical and Aerospace Engineering<br />
The Ohio State University
</p>
<h3>Abstract</h3>
<p>Most techniques developed during the past century for estimation and control of dynamical systems require precise knowledge of an underlying mathematical model. But recently, there has been renewed interest in controlling systems for which a reliable model is unknown or the model parameters can vary. Here an optimal control strategy is developed for a simple problem where the drift parameter is unknown and must be learned on the fly while controlling the system. This scenario requires a control strategy from the initial time and cannot accommodate distinct phases of parameter learning and control update. The cost function is posed over a finite time interval, and the state is subject to random disturbances and measured by a noisy sensor. Several different versions of the problem are studied. In the Bayesian version, a prior distribution on the unknown drift parameter is assumed. In the &lsquo;&lsquo;agnostic&rsquo;&rsquo; version, no such assumption is made and the performance is compared against an adversary with exact knowledge of the parameter. This gives rise to several notions of performance penalty or &lsquo;&lsquo;regret&rsquo;&rsquo;. The optimal strategy is chosen
to minimize the &lsquo;&lsquo;worst-case regret&rsquo;&rsquo; arising from the most unfavorable value of the parameter for that strategy. In every case, the optimal strategy turns out to be a Bayesian strategy or a limit of Bayesian strategies. This is a joint work with Clarence W. Rowley and Charles L. Fefferman (Princeton University).
</p>
<h3>Bio</h3>
<table class="imgtable"><tr><td>
<img src="photos/dgoswami.jpg" alt="alt text" width="220px" height="300px" />&nbsp;</td>
<td align="left"><p>Debdipta Goswami joined the Department of Mechanical and Aerospace Engineering, the Ohio State University, in 2022 as an assistant professor. He received his Ph.D. degree in Electrical and Computer Engineering from the University of Maryland in 2020 under the supervision of Prof. Derek A. Paley. Between 2020 and 2022, he has worked as a postdoctoral research associate at the Department of Mechanical and Aerospace Engineering in Princeton University where he worked with Prof. Clancy Rowley. His research interests lie at the intersection of control systems and machine learning with a focus on motion planning and agile control of aerial robots.
</p>
<p>He has worked on data-driven discovery and control of dynamical systems using operator-theoretic methods and reservoir computers. His current research focuses on the structured learning of control systems from data with guaranteed performance and simultaneous learning and control of dynamical systems. He also works on model predictive control and motion planning for unmanned aerial vehicles.
</p>
</td></tr></table>
</td>
</tr>
</table>
</body>
</html>
